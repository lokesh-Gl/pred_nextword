âœï¸ Next Word Prediction using LSTM

A simple Streamlit web application that predicts the next word in a sentence using a pre-trained LSTM model. This project demonstrates how sequence models can be used for Natural Language Processing (NLP) tasks such as text prediction.

â¸»

ğŸš€ Features (Implemented & Accurate)
	â€¢	âŒ¨ï¸ User input for a sequence of words
	â€¢	ğŸ§  Predicts the next most likely word using an LSTM model
	â€¢	ğŸ” Uses a saved tokenizer for consistent word indexing
	â€¢	ğŸ–¥ï¸ Lightweight and easy-to-use Streamlit interface
	â€¢	âš¡ Fast inference on CPU

â¸»

ğŸ§  Model Details
	â€¢	Model Type: LSTM (Long Short-Term Memory)
	â€¢	Framework: TensorFlow / Keras
	â€¢	Task: Next-word prediction (language modeling)
	â€¢	Model File: next_word_lstm.h5
	â€¢	Tokenizer File: tokenizer.pickle

The model predicts the next word by:
	1.	Tokenizing the input text
	2.	Padding the sequence to the required length
	3.	Feeding it into the LSTM model
	4.	Selecting the word with the highest predicted probability

â¸»

ğŸ› ï¸ Tech Stack
	â€¢	Frontend: Streamlit
	â€¢	Deep Learning: TensorFlow (Keras)
	â€¢	NLP Utilities: Keras Tokenizer, Padding
	â€¢	Data Handling: NumPy, Pickle

â¸»

âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the Repository
``` bash
git clone https://github.com/your-username/next-word-prediction-lstm.git
cd next-word-prediction-lstm
```
2ï¸âƒ£ Create Virtual Environment (Recommended)
``` bash 
python -m venv venv
source venv/bin/activate   # macOS / Linux
venv\Scripts\activate    # Windows
```
3ï¸âƒ£ Install Required Libraries
``` bash
pip install streamlit tensorflow numpy
```
4ï¸âƒ£ Place Required Files
``` bash
Ensure the following files are present in the project directory:

next_word_lstm.h5
tokenizer.pickle
```
5ï¸âƒ£ Run the Application
``` bash 
streamlit run app.py
```

â¸»

ğŸ§ª How the Application Works
	1.	User enters a sequence of words
	2.	Text is converted into token IDs using the tokenizer
	3.	Sequence is padded to match model input length
	4.	LSTM model predicts the probability distribution of the next word
	5.	Word with the highest probability is displayed

â¸»

ğŸ“Œ Use Cases
	â€¢	NLP learning and experimentation
	â€¢	Language modeling demonstrations
	â€¢	Text auto-completion prototypes
	â€¢	Academic mini-projects

â¸»

ğŸ” Limitations (Current Implementation)
	â€¢	Predicts only one next word
	â€¢	Accuracy depends heavily on training dataset
	â€¢	No confidence score displayed
	â€¢	No text preprocessing (lowercasing, punctuation removal) in UI

â¸»

ğŸ“ˆ Future Scope (Not Implemented)
	â€¢	Predict multiple next words
	â€¢	Display top-k predictions with probabilities
	â€¢	Add sentence auto-completion
	â€¢	Improve UI with prediction history

â¸»

ğŸ‘¨â€ğŸ’» Author

Lokesh
Student | AI / ML | Deep Learning

â¸»

ğŸ“œ License

This project is intended for academic and educational purposes.

â¸»

Sequence models like LSTM learn context to predict what comes next in language. ğŸš€
